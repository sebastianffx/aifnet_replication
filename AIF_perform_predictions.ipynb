{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import glob\n",
    "import scipy\n",
    "import os,sys\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "from scipy import ndimage\n",
    "from tensorflow import keras\n",
    "from natsort import natsorted\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from aifnet_utils.preprocess import read_nifti_file, normalize, normalize_aif, process_scan, normalize_zero_one\n",
    "from aifnet_utils.data_loaders import read_isles_volumepaths_from_file_otf, read_isles_annotations_from_file, ISLES18DataGen_aifvof_otf\n",
    "from aifnet_utils.data_loaders import delay_sequence_padding, anticipate_sequence_padding, late_bolus, early_bolus\n",
    "from aifnet_utils.results import plot_predictions\n",
    "from aifnet_utils.losses import MaxCorrelation\n",
    "from scipy import signal\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import convolution_matrix, toeplitz, circulant\n",
    "from sklearn.linear_model import Ridge\n",
    "from matplotlib import pyplot, image, transforms\n",
    "from scipy import ndimage\n",
    "from aifnet_utils.models_aifnet import get_model_twoPvols\n",
    "from numpy import inf\n",
    "from aifnet_utils.results import plot_predictions\n",
    "\n",
    "import random\n",
    "keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "%matplotlib inline\n",
    "!pwd"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/sebastian/experiments/aifnet_replication\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Reading an example PCT volume\n",
    "LOCATION = 'INSEL'\n",
    "if LOCATION == 'LOCAL':\n",
    "    ROOT_EXP = '/Users/sebastianotalora/work/postdoc/ctp/aifnet_replication/'\n",
    "    root_dir  = '/Users/sebastianotalora/work/postdoc/data/ISLES/'\n",
    "\n",
    "if LOCATION == 'INSEL':\n",
    "    ROOT_EXP = '/home/sebastian/experiments/aifnet_replication/'\n",
    "    root_dir  = '/media/sebastian/data/ASAP/ISLES2018_Training'\n",
    "\n",
    "aif_annotations_path = ROOT_EXP + 'radiologist_annotations.csv'\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "min_num_volumes_ctp = 43"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def compute_predictions_aif(model_prefix):\n",
    "    model_prefix_meassures = []\n",
    "    for current_fold in range(1,6):\n",
    "        prediction_meassures = []\n",
    "        #Reading AIFs and VOFs for each of the partitions\n",
    "        test_partition_path =  ROOT_EXP+'/partitions/fold_'+str(current_fold) +'/test_v2.txt'\n",
    "\n",
    "        aif_annotations_test, vof_annotations_test = read_isles_annotations_from_file(aif_annotations_path,  test_partition_path,\n",
    "                                                root_dir, min_num_volumes_ctp, return_aif_only = False)\n",
    "        ctp_volumes_test = read_isles_volumepaths_from_file_otf(root_dir, test_partition_path, aif_annotations_path)\n",
    "        print('======= PREDICTING USING '+ model_prefix +' FOR TEST PARTITION FOR THE FOLD ' + str(current_fold) + ' =======')\n",
    "        print(len(ctp_volumes_test), len(aif_annotations_test))\n",
    "        modelweights_path= ROOT_EXP + 'results/trained_models/aifnet_2Pvols_SGD_MaxCorr_augment_lr/'+ model_prefix+'_fold_'+str(current_fold)+'.hdf5'\n",
    "        model = get_model_twoPvols(width=256, height=256, num_channels=min_num_volumes_ctp)\n",
    "        model.load_weights(modelweights_path)\n",
    "        results_meassures, prediction_ids = [], []\n",
    "        for case_number in range(len(ctp_volumes_test)):\n",
    "            case_id = ctp_volumes_test[case_number]['image'].split('.')[-2]\n",
    "            prediction_ids.append(case_id)\n",
    "            cur_nib = nib.load(ctp_volumes_test[case_number]['image'])\n",
    "            ctp_vals = cur_nib.get_fdata()\n",
    "            x = normalize(ctp_vals[:,:,:,0:min_num_volumes_ctp])\n",
    "            if type_predictions == 'AIF':\n",
    "                y = aif_annotations_test[case_id]\n",
    "            if type_predictions == 'VOF':\n",
    "                y = vof_annotations_test[case_id]\n",
    "            prefix_fig = ROOT_EXP + '/results/predictions_aif/'+modelweights_path.split('/')[-1]+'_case_'+str(case_id) + '_'+type_predictions\n",
    "            results_meassures.append(plot_predictions(model,x,y, prefix_fig, normalize_preds=True, type_pred=type_predictions, savefig=True))\n",
    "\n",
    "        preds_fold = tfp.stats.correlation(np.array(results_meassures)[:,1,:],np.array(results_meassures)[:,0,:], sample_axis=0, event_axis=None)\n",
    "        preds_fold = preds_fold.numpy()\n",
    "        prediction_meassures.append([preds_fold.mean(),preds_fold.std(),preds_fold.var()])\n",
    "        model_prefix_meassures.append(prediction_meassures)\n",
    "        np.savetxt('results/'+model_prefix+'pearson_fold_'+str(current_fold)+'.csv', prediction_meassures, delimiter=',',fmt='%1.5f')\n",
    "        np.savetxt('results/'+model_prefix+'allpreds_fold_'+str(current_fold)+'.csv', np.array(results_meassures)[:,1,:], delimiter=',',fmt='%1.5f')\n",
    "\n",
    "        test_ids_file=open('results/'+model_prefix+'pred_ids_fold_'+str(current_fold)+'.csv','w')\n",
    "        for element in prediction_ids:        \n",
    "            test_ids_file.write(element+'\\n')\n",
    "        test_ids_file.close()\n",
    "    model_prefix_meassures = np.array(model_prefix_meassures)\n",
    "    np.savetxt('results/'+model_prefix+'pearson_ALLFOLDS.csv', model_prefix_meassures.mean(axis=0), delimiter=',',fmt='%1.5f')\n",
    "    return model_prefix_meassures.mean(axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "last_trained_model_paths = glob.glob('/home/sebastian/experiments/aifnet_replication/results/*_mse_augment_lr0.14205136895431247_fold_3*')\n",
    "last_prefixes = []\n",
    "for item in last_trained_model_paths:\n",
    "    prefix_path = item.split('/')[-1].split('_fold')[0]\n",
    "    if prefix_path not in set(last_prefixes):\n",
    "        last_prefixes.append(prefix_path)\n",
    "print(len(last_prefixes))\n",
    "print(len(last_trained_model_paths))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "type_predictions = 'AIF'\n",
    "for model_prefix in last_prefixes:\n",
    "    print(compute_predictions_aif(model_prefix))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cba59e4a102b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtype_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'AIF'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_prefix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlast_prefixes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_predictions_aif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-730a4d255639>\u001b[0m in \u001b[0;36mcompute_predictions_aif\u001b[0;34m(model_prefix)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtest_partition_path\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mROOT_EXP\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/partitions/fold_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_fold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/test_v2.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         aif_annotations_test, vof_annotations_test = read_isles_annotations_from_file(aif_annotations_path,  test_partition_path,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                                 root_dir, min_num_volumes_ctp, return_aif_only = False)\n\u001b[1;32m     10\u001b[0m         \u001b[0mctp_volumes_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_isles_volumepaths_from_file_otf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_partition_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maif_annotations_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/experiments/aifnet_replication/aifnet_utils/data_loaders.py\u001b[0m in \u001b[0;36mread_isles_annotations_from_file\u001b[0;34m(aif_annotations_path, partition_file_path, root_dir, minimum_number_volumes_ctp, return_aif_only)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mvofs_cases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_case\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVOF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mminimum_number_volumes_ctp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Since not all the CTP sequences have the same #volumes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mctp_vals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_aif_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "model_path = '/home/sebastian/experiments/aifnet_replication/results/aifnet_2Pvols_SGD_mse_augment_lr0.14205136895431247_fold_3.hdf5'\n",
    "prediction_meassures = []\n",
    "model_prefix_meassures = []\n",
    "type_predictions = 'BOTH'\n",
    "current_fold = 3\n",
    "#Reading AIFs and VOFs for each of the partitions\n",
    "test_partition_path =  ROOT_EXP+'/partitions/fold_'+str(current_fold) +'/test_v2.txt'\n",
    "\n",
    "aif_annotations_test, vof_annotations_test = read_isles_annotations_from_file(aif_annotations_path,  test_partition_path,\n",
    "                                        root_dir, min_num_volumes_ctp, return_aif_only = False)\n",
    "\n",
    "ctp_volumes_test = read_isles_volumepaths_from_file_otf(root_dir, test_partition_path, aif_annotations_path)\n",
    "print('======= PREDICTING USING '+ model_prefix +' FOR TEST PARTITION FOR THE FOLD ' + str(current_fold) + ' =======')\n",
    "print(len(ctp_volumes_test), len(aif_annotations_test))\n",
    "modelweights_path= model_path#ROOT_EXP + 'results/trained_models/aifnet_2Pvols_SGD_MaxCorr_augment_lr/'+ model_prefix+'_fold_'+str(current_fold)+'.hdf5'\n",
    "model = get_model_twoPvols(width=256, height=256, num_channels=min_num_volumes_ctp)\n",
    "model.load_weights(modelweights_path)\n",
    "results_meassures, prediction_ids = [], []\n",
    "for case_number in range(len(ctp_volumes_test)):\n",
    "    case_id = ctp_volumes_test[case_number]['image'].split('.')[-2]\n",
    "    prediction_ids.append(case_id)\n",
    "    cur_nib = nib.load(ctp_volumes_test[case_number]['image'])\n",
    "    ctp_vals = cur_nib.get_fdata()\n",
    "    x = normalize(ctp_vals[:,:,:,0:min_num_volumes_ctp])\n",
    "    if type_predictions == 'AIF':\n",
    "        y = aif_annotations_test[case_id]\n",
    "    if type_predictions == 'VOF':\n",
    "        y = vof_annotations_test[case_id]\n",
    "    if type_predictions == 'BOTH':\n",
    "        y = [aif_annotations_test[case_id],vof_annotations_test[case_id]]\n",
    "\n",
    "    prefix_fig = ROOT_EXP + '/results/predictions_aif/'+modelweights_path.split('/')[-1]+'_case_'+str(case_id) + '_'+type_predictions\n",
    "    results_meassures.append(plot_predictions(model,x,y, prefix_fig, normalize_preds=True, type_pred=type_predictions, savefig=True))\n",
    "\n",
    "# preds_fold = tfp.stats.correlation(np.array(results_meassures)[:,1,:],np.array(results_meassures)[:,0,:], sample_axis=0, event_axis=None)\n",
    "# preds_fold = preds_fold.numpy()\n",
    "# prediction_meassures.append([preds_fold.mean(),preds_fold.std(),preds_fold.var()])\n",
    "# model_prefix_meassures.append(prediction_meassures)\n",
    "# np.savetxt('results/'+model_prefix+'pearson_fold_'+str(current_fold)+'.csv', prediction_meassures, delimiter=',',fmt='%1.5f')\n",
    "# np.savetxt('results/'+model_prefix+'allpreds_fold_'+str(current_fold)+'.csv', np.array(results_meassures)[:,1,:], delimiter=',',fmt='%1.5f')\n",
    "\n",
    "# test_ids_file=open('results/'+model_prefix+'pred_ids_fold_'+str(current_fold)+'.csv','w')\n",
    "# for element in prediction_ids:        \n",
    "#     test_ids_file.write(element+'\\n')\n",
    "# test_ids_file.close()\n",
    "# model_prefix_meassures = np.array(model_prefix_meassures)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= PREDICTING USING aifnet_2Pvols_SGD_mse_augment_lr0.14205136895431247 FOR TEST PARTITION FOR THE FOLD 3 =======\n",
      "32 32\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-15-e9936fea0905>:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  preds_fold = tfp.stats.correlation(np.array(results_meassures)[:,1,:],np.array(results_meassures)[:,0,:], sample_axis=0, event_axis=None)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e9936fea0905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mresults_meassures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix_fig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_preds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mpreds_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_meassures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_meassures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mpreds_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds_fold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprediction_meassures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds_fold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds_fold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds_fold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('aifnet': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "03674a9a762e7c88d6ffee8451a96bad54270149f3e842460d737eee38e8f064"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}