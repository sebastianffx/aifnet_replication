{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import glob\n",
    "import scipy\n",
    "import os,sys\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "from scipy import ndimage\n",
    "from tensorflow import keras\n",
    "from natsort import natsorted\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from aifnet_utils.preprocess import read_nifti_file, normalize, normalize_aif, process_scan, normalize_zero_one\n",
    "from aifnet_utils.data_loaders import read_isles_volumepaths_from_file_otf, read_isles_annotations_from_file, ISLES18DataGen_aifvof_otf\n",
    "from aifnet_utils.data_loaders import delay_sequence_padding, anticipate_sequence_padding, late_bolus, early_bolus\n",
    "from aifnet_utils.results import plot_predictions\n",
    "from aifnet_utils.losses import MaxCorrelation\n",
    "from scipy import signal\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import convolution_matrix, toeplitz, circulant\n",
    "from sklearn.linear_model import Ridge\n",
    "from matplotlib import pyplot, image, transforms\n",
    "from scipy import ndimage\n",
    "from aifnet_utils.models_aifnet import get_model_twoPvols\n",
    "from numpy import inf\n",
    "from aifnet_utils.results import plot_predictions\n",
    "\n",
    "import random\n",
    "keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "%matplotlib inline\n",
    "!pwd"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/Users/sebastianotalora/work/postdoc/ctp/aifnet_replication\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Reading an example PCT volume\n",
    "LOCATION = 'LOCAL'\n",
    "if LOCATION == 'LOCAL':\n",
    "    ROOT_EXP = '/Users/sebastianotalora/work/postdoc/ctp/aifnet_replication/'\n",
    "    root_dir  = '/Users/sebastianotalora/work/postdoc/data/ISLES/'\n",
    "\n",
    "if LOCATION == 'INSEL':\n",
    "    ROOT_EXP = '/home/sebastian/experiments/aifnet_replication/'\n",
    "    root_dir  = '/media/sebastian/data/ASAP/ISLES2018_Training'\n",
    "\n",
    "aif_annotations_path = ROOT_EXP + 'radiologist_annotations.csv'\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "min_num_volumes_ctp = 43"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def compute_predictions_aif(model_prefix):\n",
    "    model_prefix_meassures = []\n",
    "    for current_fold in range(1,6):\n",
    "        prediction_meassures = []\n",
    "        #Reading AIFs and VOFs for each of the partitions\n",
    "        test_partition_path =  ROOT_EXP+'/partitions/fold_'+str(current_fold) +'/test_v2.txt'\n",
    "\n",
    "        aif_annotations_test, vof_annotations_test = read_isles_annotations_from_file(aif_annotations_path,  test_partition_path,\n",
    "                                                root_dir, min_num_volumes_ctp, return_aif_only = False)\n",
    "        ctp_volumes_test = read_isles_volumepaths_from_file_otf(root_dir, test_partition_path, aif_annotations_path)\n",
    "        print('======= PREDICTING USING '+ model_prefix +' FOR TEST PARTITION FOR THE FOLD ' + str(current_fold) + ' =======')\n",
    "        print(len(ctp_volumes_test), len(aif_annotations_test))\n",
    "        modelweights_path= ROOT_EXP + 'results/trained_models/aifnet_2Pvols_SGD_MaxCorr_augment_lr/'+ model_prefix+'_fold_'+str(current_fold)+'.hdf5'\n",
    "        model = get_model_twoPvols(width=256, height=256, num_channels=min_num_volumes_ctp)\n",
    "        model.load_weights(modelweights_path)\n",
    "        results_meassures, prediction_ids = [], []\n",
    "        for case_number in range(len(ctp_volumes_test)):\n",
    "            case_id = ctp_volumes_test[case_number]['image'].split('.')[-2]\n",
    "            prediction_ids.append(case_id)\n",
    "            cur_nib = nib.load(ctp_volumes_test[case_number]['image'])\n",
    "            ctp_vals = cur_nib.get_fdata()\n",
    "            x = normalize(ctp_vals[:,:,:,0:min_num_volumes_ctp])\n",
    "            if type_predictions == 'AIF':\n",
    "                y = aif_annotations_test[case_id]\n",
    "            if type_predictions == 'VOF':\n",
    "                y = vof_annotations_test[case_id]\n",
    "            prefix_fig = ROOT_EXP + '/results/predictions_aif/'+modelweights_path.split('/')[-1]+'_case_'+str(case_id)\n",
    "            results_meassures.append(plot_predictions(model,x,y, prefix_fig, normalize_preds=True, type_pred=type_predictions, savefig=True))\n",
    "\n",
    "        preds_fold = tfp.stats.correlation(np.array(results_meassures)[:,1,:],np.array(results_meassures)[:,0,:], sample_axis=0, event_axis=None)\n",
    "        preds_fold = preds_fold.numpy()\n",
    "        prediction_meassures.append([preds_fold.mean(),preds_fold.std(),preds_fold.var()])\n",
    "        model_prefix_meassures.append(prediction_meassures)\n",
    "        np.savetxt('results/'+model_prefix+'pearson_fold_'+str(current_fold)+'.csv', prediction_meassures, delimiter=',',fmt='%1.5f')\n",
    "        np.savetxt('results/'+model_prefix+'allpreds_fold_'+str(current_fold)+'.csv', np.array(results_meassures)[:,1,:], delimiter=',',fmt='%1.5f')\n",
    "\n",
    "        test_ids_file=open('results/'+model_prefix+'pred_ids_fold_'+str(current_fold)+'.csv','w')\n",
    "        for element in prediction_ids:        \n",
    "            test_ids_file.write(element+'\\n')\n",
    "        test_ids_file.close()\n",
    "    model_prefix_meassures = np.array(model_prefix_meassures)\n",
    "    np.savetxt('results/'+model_prefix+'pearson_ALLFOLDS.csv', model_prefix_meassures.mean(axis=0), delimiter=',',fmt='%1.5f')\n",
    "    return model_prefix_meassures.mean(axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "last_trained_model_paths = glob.glob('/Users/sebastianotalora/work/postdoc/ctp/aifnet_replication/results/trained_models/aifnet_2Pvols_SGD_MaxCorr_augment_lr/*')\n",
    "last_prefixes = []\n",
    "for item in last_trained_model_paths:\n",
    "    prefix_path = item.split('/')[-1].split('_fold')[0]\n",
    "    if prefix_path not in set(last_prefixes):\n",
    "        last_prefixes.append(prefix_path)\n",
    "print(len(last_prefixes))\n",
    "print(len(last_trained_model_paths))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15\n",
      "75\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "type_predictions = 'AIF'\n",
    "for model_prefix in last_prefixes:\n",
    "    print(compute_predictions_aif(model_prefix))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======= PREDICTING USING aifnet_2Pvols_SGD_MaxCorr_augment_lr0.9623209115272406 FOR TEST PARTITION FOR THE FOLD 1 =======\n",
      "31 31\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '/Users/sebastianotalora/work/postdoc/ctp/aifnet_replication/results/trained_models/models_14_09_21/aifnet_2Pvols_SGD_MaxCorr_augment_lr0.9623209115272406_fold_1.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cba59e4a102b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtype_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'AIF'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_prefix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlast_prefixes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_predictions_aif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-daddeae9a356>\u001b[0m in \u001b[0;36mcompute_predictions_aif\u001b[0;34m(model_prefix)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodelweights_path\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mROOT_EXP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'results/trained_models/models_14_09_21/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mmodel_prefix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_fold_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.hdf5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_twoPvols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_num_volumes_ctp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mresults_meassures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcase_number\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctp_volumes_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2317\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2318\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2319\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2320\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/Users/sebastianotalora/work/postdoc/ctp/aifnet_replication/results/trained_models/models_14_09_21/aifnet_2Pvols_SGD_MaxCorr_augment_lr0.9623209115272406_fold_1.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "last_prefixes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['aifnet_2Pvols_SGD_mse_augment_lr0.8923848003155606',\n",
       " 'aifnet_2Pvols_SGD_mse_augment_lr5.197918264960655e-06',\n",
       " 'aifnet_2Pvols_SGD_mse_augment_lr0.26664456007954873',\n",
       " 'aifnet_2Pvols_SGD_mse_augment_lr0.24466717332886467',\n",
       " 'aifnet_2Pvols_SGD_mse_augment_lr0.8286085065732829',\n",
       " 'aifnet_2Pvols_SGD_mse_augment_lr0.019013083285230357',\n",
       " 'aifnet_2Pvols_SGD_mse_augment_lr0.0012656176411610413',\n",
       " 'aifnet_2Pvols_SGD_mse_augment_lr0.6930557976225901',\n",
       " 'aifnet_2Pvols_SGD_mse_augment_lr5.156127099319659e-06',\n",
       " 'aifnet_2Pvols_SGD_mse_augment_lr0.31965383057547536',\n",
       " 'aifnet_2Pvols_SGD_mse_augment_lr0.32219260475608635',\n",
       " 'aifnet_2Pvols_SGD_mse_augment_lr0.18557241904693844',\n",
       " 'aifnet_2Pvols_SGD_mse_augment_lr0.41756190770883805',\n",
       " 'aifnet_2Pvols_SGD_mse_augment_lr0.04584660141746011',\n",
       " 'aifnet_2Pvols_SGD_mse_augment_lr0.14205136895431247']"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}